# ============================================
# Sophia Intel AI - Environment Configuration
# ============================================
# Copy this file to .env.local and fill in your API keys

# ============================================
# CORE API KEYS (Required)
# ============================================
# OpenAI API Key - https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# OpenRouter API Key - https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-...

# Portkey API Key - https://portkey.ai/dashboard
PORTKEY_API_KEY=...

# ============================================
# OPTIONAL SERVICES
# ============================================
# Together AI for embeddings - https://api.together.xyz/
TOGETHER_API_KEY=...

# Pulumi for infrastructure - https://app.pulumi.com/
PULUMI_ACCESS_TOKEN=pul-...

# ============================================
# SERVER CONFIGURATION
# ============================================
# API Server Port
AGENT_API_PORT=8003

# UI Server Port
AGENT_UI_PORT=3000

# Development Mode (enables debug endpoints)
LOCAL_DEV_MODE=false

# Default model pool (premium/balanced/free)
DEFAULT_MODEL_POOL=balanced

# ============================================
# DATABASE CONFIGURATION (Production)
# ============================================
# PostgreSQL Connection String
# DATABASE_URL=postgresql://user:password@localhost:5432/sophia_intel

# Redis Connection String  
# REDIS_URL=redis://localhost:6379

# FAISS Index Path (for vector storage)
# FAISS_INDEX_PATH=/data/faiss_index

# Weaviate Configuration
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=
WEAVIATE_COLLECTION_A=CodeChunk_A
WEAVIATE_COLLECTION_B=CodeChunk_B

# ============================================
# SECURITY CONFIGURATION
# ============================================
# Allowed CORS Origins (comma-separated)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8003

# Rate Limiting
ENABLE_RATE_LIMIT=false
RATE_LIMIT_PER_MINUTE=60

# JWT Secret for Authentication
# JWT_SECRET=your-secret-key-here

# Enable Audit Logging
ENABLE_AUDIT_LOG=false

# ============================================
# FEATURE FLAGS
# ============================================
# MCP Server Features
ENABLE_MCP_FILESYSTEM=true
ENABLE_MCP_GIT=true
ENABLE_MCP_SUPERMEMORY=true

# Experimental Features
ENABLE_GRAPHRAG=false
ENABLE_STREAMING=true

# ============================================
# MODEL CONFIGURATION
# ============================================
# Latest Models (August 2025)
LEAD_MODEL=openai/gpt-5
CRITIC_MODEL=anthropic/claude-4-opus
JUDGE_MODEL=openai/gpt-5
RUNNER_MODEL=anthropic/claude-4-sonnet
GENERATOR_MODEL_DEFAULT=google/gemini-2.5-pro

# Model Selection Strategy
MODEL_SELECTION_STRATEGY=balanced  # cost-optimized/performance/balanced

# Maximum tokens for responses
MAX_TOKENS=4000

# Default temperature
DEFAULT_TEMPERATURE=0.7

# ============================================
# EMBEDDING CONFIGURATION
# ============================================
# Tier A: Long context, high accuracy (32k tokens)
EMBED_MODEL_A=togethercomputer/m2-bert-80M-32k-retrieval
EMBED_DIM_A=768

# Tier B: Fast, frequent use
EMBED_MODEL_B=BAAI/bge-large-en-v1.5
EMBED_DIM_B=1024

# ============================================
# MEMORY & SEARCH CONFIGURATION
# ============================================
# Memory retention days
MEMORY_RETENTION_DAYS=30

# Search result limit
DEFAULT_SEARCH_LIMIT=10

# Enable semantic search
ENABLE_SEMANTIC_SEARCH=true

# Enable BM25 search
ENABLE_BM25_SEARCH=true

# Enable reranking
ENABLE_RERANKING=true

# ============================================
# MONITORING & OBSERVABILITY
# ============================================
# Sentry DSN for error tracking
# SENTRY_DSN=https://...@sentry.io/...

# Prometheus metrics endpoint
# ENABLE_METRICS=true
# METRICS_PORT=9090

# ============================================
# DEPLOYMENT CONFIGURATION
# ============================================
# Environment (development/staging/production)
ENVIRONMENT=development

# AWS Region (for S3, etc.)
# AWS_REGION=us-west-2

# GCP Project ID
# GCP_PROJECT_ID=sophia-intel-ai

# Azure Resource Group
# AZURE_RESOURCE_GROUP=sophia-intel-rg

# ============================================
# PORTKEY GATEWAY CONFIGURATION
# ============================================
# For chat models (OpenRouter via Portkey)
OPENAI_BASE_URL=https://api.portkey.ai/v1

# Request metadata
HTTP_REFERER=http://localhost:3000
X_TITLE=sophia-intel-ai

# Development
PLAYGROUND_PORT=7777