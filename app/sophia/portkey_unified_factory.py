"""
Sophia Portkey-Integrated Business Intelligence Factory
Extends the Sophia factory with Portkey routing for all LLM operations
"""

import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any, Optional
from uuid import uuid4

from app.core.portkey_config import PortkeyManager, get_portkey_manager
from app.core.vector_db_config import get_vector_db_manager
from app.memory.unified_memory import store_memory

logger = logging.getLogger(__name__)


# ==============================================================================
# SOPHIA BUSINESS AGENT TYPES
# ==============================================================================


class BusinessAgentRole(str):
    """Business intelligence roles for Sophia agents"""

    MARKET_ANALYST = "market_analyst"
    SALES_STRATEGIST = "sales_strategist"
    CUSTOMER_SUCCESS = "customer_success"
    PRODUCT_MANAGER = "product_manager"
    BUSINESS_ANALYST = "business_analyst"
    FINANCIAL_ANALYST = "financial_analyst"
    COMPETITIVE_INTELLIGENCE = "competitive_intelligence"
    GROWTH_STRATEGIST = "growth_strategist"
    DATA_SCIENTIST = "data_scientist"


class BusinessPersonality(str):
    """Business personality traits for Sophia agents"""

    STRATEGIC_VISIONARY = "strategic_visionary"
    DATA_DRIVEN_ANALYTICAL = "data_driven_analytical"
    CUSTOMER_CENTRIC = "customer_centric"
    INNOVATIVE_CREATIVE = "innovative_creative"
    RESULTS_ORIENTED = "results_oriented"


# ==============================================================================
# DATA MODELS
# ==============================================================================


@dataclass
class SophiaAgentProfile:
    """Profile for Sophia business intelligence agents"""

    id: str
    name: str
    role: str
    model: str
    specialty: str
    personality: Optional[str] = None
    business_domain: str = "general"
    expertise_areas: list[str] = field(default_factory=list)
    tools: list[str] = field(default_factory=list)
    virtual_key: str = "openai-vk-190a60"
    integrations: list[str] = field(default_factory=list)
    performance_metrics: dict[str, float] = field(default_factory=dict)


@dataclass
class BusinessInsight:
    """Business insight generated by Sophia agents"""

    id: str
    agent_id: str
    insight_type: str
    content: str
    confidence: float
    supporting_data: dict[str, Any]
    recommendations: list[str]
    created_at: datetime


# ==============================================================================
# SOPHIA PORTKEY FACTORY CLASS
# ==============================================================================


class PortkeySophiaFactory:
    """
    Enhanced Sophia Factory with Portkey integration for business intelligence
    """

    def __init__(self):
        self.portkey_manager: PortkeyManager = get_portkey_manager()
        self.vector_db = get_vector_db_manager()
        self.domain = "SOPHIA"
        self._initialize_portkey_routing()

    def _initialize_portkey_routing(self):
        """Initialize Portkey routing configuration for business agents"""
        # Map business roles to optimal providers
        self.role_provider_mapping = {
            BusinessAgentRole.MARKET_ANALYST: "perplexity",  # Real-time market data
            BusinessAgentRole.SALES_STRATEGIST: "openai",
            BusinessAgentRole.CUSTOMER_SUCCESS: "anthropic",  # Empathetic responses
            BusinessAgentRole.PRODUCT_MANAGER: "anthropic",
            BusinessAgentRole.BUSINESS_ANALYST: "openai",
            BusinessAgentRole.FINANCIAL_ANALYST: "deepseek",  # Numerical analysis
            BusinessAgentRole.COMPETITIVE_INTELLIGENCE: "perplexity",  # Web search
            BusinessAgentRole.GROWTH_STRATEGIST: "gemini",
            BusinessAgentRole.DATA_SCIENTIST: "cohere",  # Data analysis
        }

        # Model selection for business use cases
        self.provider_model_mapping = {
            "openai": "gpt-4-turbo",
            "anthropic": "claude-3-sonnet",
            "perplexity": "pplx-70b-online",  # Real-time data
            "deepseek": "deepseek-chat",
            "gemini": "gemini-1.5-pro",
            "cohere": "command-r-plus",
            "groq": "mixtral-8x7b-32768",
            "mistral": "mistral-medium",
            "xai": "grok-beta",
        }

        logger.info("Portkey routing initialized for Sophia Factory")

    async def create_business_agent(
        self,
        name: str,
        role: str,
        specialty: str = None,
        business_domain: str = "general",
        **kwargs,
    ) -> SophiaAgentProfile:
        """
        Create a business intelligence agent with Portkey routing

        Args:
            name: Agent name
            role: Business role
            specialty: Optional specialty
            business_domain: Business domain focus
            **kwargs: Additional configuration

        Returns:
            Configured SophiaAgentProfile with Portkey routing
        """
        # Determine optimal provider for role
        provider = self.role_provider_mapping.get(role, "openai")
        model = self.provider_model_mapping.get(provider, "gpt-4")

        # Get virtual key for provider
        virtual_key = self.portkey_manager.get_virtual_key(provider)

        if not virtual_key:
            logger.warning(f"No virtual key for {provider}, falling back to OpenAI")
            provider = "openai"
            virtual_key = self.portkey_manager.get_virtual_key("openai")

        # Create agent profile
        agent_profile = SophiaAgentProfile(
            id=str(uuid4()),
            name=name,
            role=role,
            model=model,
            specialty=specialty or role,
            business_domain=business_domain,
            virtual_key=virtual_key,
            expertise_areas=self._get_role_expertise(role),
            tools=self._get_role_tools(role),
            integrations=self._get_role_integrations(role),
            performance_metrics={"accuracy": 0.0, "response_time": 0.0, "insights_generated": 0},
        )

        # Store in memory
        await self._store_agent_in_memory(agent_profile)

        # Store in vector DB for semantic search
        if self.vector_db.qdrant:
            await self._store_agent_in_vector_db(agent_profile)

        return agent_profile

    def _get_role_expertise(self, role: str) -> list[str]:
        """Get expertise areas based on role"""
        expertise_map = {
            BusinessAgentRole.MARKET_ANALYST: [
                "market_research",
                "trend_analysis",
                "competitor_analysis",
                "industry_insights",
            ],
            BusinessAgentRole.SALES_STRATEGIST: [
                "sales_forecasting",
                "pipeline_management",
                "deal_optimization",
                "territory_planning",
            ],
            BusinessAgentRole.CUSTOMER_SUCCESS: [
                "customer_retention",
                "satisfaction_analysis",
                "churn_prediction",
                "upsell_identification",
            ],
            BusinessAgentRole.PRODUCT_MANAGER: [
                "product_strategy",
                "roadmap_planning",
                "feature_prioritization",
                "user_research",
            ],
            BusinessAgentRole.BUSINESS_ANALYST: [
                "process_optimization",
                "requirements_analysis",
                "data_modeling",
                "reporting",
            ],
            BusinessAgentRole.FINANCIAL_ANALYST: [
                "financial_modeling",
                "budget_analysis",
                "roi_calculation",
                "risk_assessment",
            ],
            BusinessAgentRole.COMPETITIVE_INTELLIGENCE: [
                "competitor_monitoring",
                "market_positioning",
                "swot_analysis",
                "pricing_strategy",
            ],
            BusinessAgentRole.GROWTH_STRATEGIST: [
                "growth_hacking",
                "acquisition_strategy",
                "retention_optimization",
                "viral_marketing",
            ],
            BusinessAgentRole.DATA_SCIENTIST: [
                "predictive_modeling",
                "statistical_analysis",
                "machine_learning",
                "data_visualization",
            ],
        }
        return expertise_map.get(role, ["general_business_analysis"])

    def _get_role_tools(self, role: str) -> list[str]:
        """Get tools based on role"""
        tools_map = {
            BusinessAgentRole.MARKET_ANALYST: [
                "web_scraper",
                "trend_analyzer",
                "sentiment_analyzer",
                "news_aggregator",
            ],
            BusinessAgentRole.SALES_STRATEGIST: [
                "crm_analyzer",
                "pipeline_optimizer",
                "forecast_model",
                "territory_mapper",
            ],
            BusinessAgentRole.CUSTOMER_SUCCESS: [
                "nps_calculator",
                "churn_predictor",
                "health_scorer",
                "feedback_analyzer",
            ],
            BusinessAgentRole.FINANCIAL_ANALYST: [
                "financial_calculator",
                "budget_tracker",
                "roi_analyzer",
                "risk_modeler",
            ],
            BusinessAgentRole.DATA_SCIENTIST: [
                "data_preprocessor",
                "model_trainer",
                "feature_engineer",
                "visualization_tool",
            ],
        }
        return tools_map.get(role, ["data_analyzer", "report_generator"])

    def _get_role_integrations(self, role: str) -> list[str]:
        """Get integrations based on role"""
        integrations_map = {
            BusinessAgentRole.SALES_STRATEGIST: ["salesforce", "hubspot", "gong"],
            BusinessAgentRole.CUSTOMER_SUCCESS: ["zendesk", "intercom", "gainsight"],
            BusinessAgentRole.MARKET_ANALYST: ["google_analytics", "semrush", "ahrefs"],
            BusinessAgentRole.FINANCIAL_ANALYST: ["quickbooks", "xero", "tableau"],
            BusinessAgentRole.DATA_SCIENTIST: ["databricks", "snowflake", "bigquery"],
        }
        return integrations_map.get(role, ["slack", "email"])

    async def _store_agent_in_memory(self, agent: SophiaAgentProfile):
        """Store agent profile in memory system"""
        try:
            memory_data = {
                "id": agent.id,
                "name": agent.name,
                "role": agent.role,
                "model": agent.model,
                "business_domain": agent.business_domain,
                "virtual_key": agent.virtual_key,
                "created_at": datetime.now(timezone.utc).isoformat(),
            }

            await store_memory(
                memory_id=f"sophia_agent_{agent.id}",
                memory_type="agent_profile",
                content=json.dumps(memory_data),
                metadata={
                    "domain": "SOPHIA",
                    "role": agent.role,
                    "business_domain": agent.business_domain,
                },
            )
            logger.debug(f"Stored agent {agent.name} in memory")
        except Exception as e:
            logger.error(f"Failed to store agent in memory: {e}")

    async def _store_agent_in_vector_db(self, agent: SophiaAgentProfile):
        """Store agent profile in vector database"""
        try:
            # Create text representation for embedding
            agent_text = f"""
            Business Agent: {agent.name}
            Role: {agent.role}
            Specialty: {agent.specialty}
            Domain: {agent.business_domain}
            Expertise: {', '.join(agent.expertise_areas)}
            Tools: {', '.join(agent.tools)}
            Integrations: {', '.join(agent.integrations)}
            Model: {agent.model}
            """

            # Generate embedding using Portkey
            embedding_response = self.portkey_manager.create_embedding(
                provider="openai", model="text-embedding-3-small", input_text=agent_text
            )

            if embedding_response and hasattr(embedding_response, "data"):
                vector = embedding_response.data[0].embedding

                # Store in Qdrant
                self.vector_db.store_vector(
                    db_type="qdrant",
                    collection="sophia_knowledge",
                    vector=vector,
                    payload={
                        "agent_id": agent.id,
                        "name": agent.name,
                        "role": agent.role,
                        "specialty": agent.specialty,
                        "business_domain": agent.business_domain,
                        "model": agent.model,
                        "created_at": datetime.now(timezone.utc).isoformat(),
                    },
                    id=agent.id,
                )
                logger.debug(f"Stored agent {agent.name} in vector database")
        except Exception as e:
            logger.error(f"Failed to store agent in vector DB: {e}")

    async def generate_business_insight(
        self,
        agent: SophiaAgentProfile,
        query: str,
        context: dict[str, Any] = None,
        temperature: float = 0.7,
        max_tokens: int = 2000,
    ) -> BusinessInsight:
        """
        Generate business insight using Portkey routing

        Args:
            agent: Agent profile
            query: Business query
            context: Additional context
            temperature: Generation temperature
            max_tokens: Maximum tokens

        Returns:
            BusinessInsight object
        """
        provider = self.role_provider_mapping.get(agent.role, "openai")

        try:
            # Prepare messages with business context
            messages = [
                {"role": "system", "content": self._generate_business_prompt(agent)},
                {
                    "role": "user",
                    "content": f"{query}\n\nContext: {json.dumps(context) if context else 'None'}",
                },
            ]

            # Check cache first
            cache_key = f"sophia:{agent.id}:{hash(query)}"
            if self.vector_db.redis:
                cached = self.vector_db.cache_get(cache_key)
                if cached:
                    logger.debug(f"Using cached response for {agent.name}")
                    return json.loads(cached)

            # Execute with Portkey
            start_time = datetime.now(timezone.utc)
            response = self.portkey_manager.create_completion(
                provider=provider,
                model=agent.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
            )
            execution_time = (datetime.now(timezone.utc) - start_time).total_seconds()

            if response and hasattr(response, "choices"):
                content = response.choices[0].message.content

                # Parse and structure the insight
                insight = BusinessInsight(
                    id=str(uuid4()),
                    agent_id=agent.id,
                    insight_type=agent.role,
                    content=content,
                    confidence=0.85,  # Could be calculated based on model confidence
                    supporting_data=context or {},
                    recommendations=self._extract_recommendations(content),
                    created_at=datetime.now(timezone.utc),
                )

                # Cache the result
                if self.vector_db.redis:
                    self.vector_db.cache_set(
                        cache_key,
                        json.dumps(
                            {
                                "id": insight.id,
                                "content": insight.content,
                                "recommendations": insight.recommendations,
                            }
                        ),
                        ttl=3600,
                    )

                # Store in Mem0 for learning
                if self.vector_db.mem0:
                    self.vector_db.add_memory(
                        user_id=agent.id,
                        content=f"Query: {query[:100]}... Insight: {content[:200]}...",
                        metadata={
                            "agent": agent.name,
                            "role": agent.role,
                            "domain": agent.business_domain,
                            "execution_time": execution_time,
                        },
                    )

                # Update agent metrics
                agent.performance_metrics["insights_generated"] += 1
                agent.performance_metrics["response_time"] = execution_time

                return insight
            else:
                raise ValueError("Invalid response from Portkey")

        except Exception as e:
            logger.error(f"Failed to generate insight for agent {agent.name}: {e}")

            # Create error insight
            return BusinessInsight(
                id=str(uuid4()),
                agent_id=agent.id,
                insight_type="error",
                content=f"Failed to generate insight: {str(e)}",
                confidence=0.0,
                supporting_data={},
                recommendations=[],
                created_at=datetime.now(timezone.utc),
            )

    def _generate_business_prompt(self, agent: SophiaAgentProfile) -> str:
        """Generate business-focused system prompt"""
        return f"""You are {agent.name}, a specialized {agent.role} in the Sophia Business Intelligence System.

Your business domain expertise: {agent.business_domain}

Your areas of expertise include:
{chr(10).join(f"- {area}" for area in agent.expertise_areas)}

You have access to these analytical tools:
{chr(10).join(f"- {tool}" for tool in agent.tools)}

You integrate with these systems:
{chr(10).join(f"- {integration}" for integration in agent.integrations)}

Operating Guidelines:
- Provide data-driven insights backed by evidence
- Focus on actionable recommendations
- Consider business impact and ROI
- Identify risks and opportunities
- Use clear, executive-friendly language
- Quantify impacts when possible

Your responses should be strategic, insightful, and focused on driving business value."""

    def _extract_recommendations(self, content: str) -> list[str]:
        """Extract recommendations from insight content"""
        recommendations = []

        # Simple extraction based on common patterns
        lines = content.split("\n")
        for line in lines:
            line = line.strip()
            if any(
                keyword in line.lower()
                for keyword in ["recommend", "suggest", "should", "consider", "advise"]
            ):
                if line.startswith("-") or line.startswith("â€¢") or line.startswith("*"):
                    recommendations.append(line[1:].strip())
                elif ":" in line:
                    recommendations.append(line.split(":", 1)[1].strip())

        return recommendations[:5]  # Limit to top 5 recommendations

    async def create_business_team(
        self, team_name: str, objective: str, required_roles: list[str], **kwargs
    ) -> dict[str, Any]:
        """
        Create a team of business agents with diverse providers

        Args:
            team_name: Name of the team
            objective: Team objective
            required_roles: List of required roles
            **kwargs: Additional configuration

        Returns:
            Team configuration
        """
        agents = []

        # Create agents for each required role
        for role in required_roles:
            agent = await self.create_business_agent(
                name=f"{team_name}_{role}",
                role=role,
                specialty=objective,
                business_domain=kwargs.get("business_domain", "general"),
            )
            agents.append(agent)

        team_config = {
            "id": str(uuid4()),
            "name": team_name,
            "objective": objective,
            "agents": [
                {
                    "id": agent.id,
                    "name": agent.name,
                    "role": agent.role,
                    "model": agent.model,
                    "provider": self.role_provider_mapping.get(agent.role, "openai"),
                }
                for agent in agents
            ],
            "created_at": datetime.now(timezone.utc).isoformat(),
            "portkey_enabled": True,
        }

        # Store team configuration
        await store_memory(
            memory_id=f"sophia_team_{team_config['id']}",
            memory_type="team_config",
            content=json.dumps(team_config),
            metadata={"domain": "SOPHIA", "objective": objective, "agent_count": len(agents)},
        )

        return team_config

    async def search_similar_insights(self, query: str, limit: int = 5) -> list[dict[str, Any]]:
        """Search for similar business insights in vector database"""
        try:
            # Generate embedding for query
            embedding_response = self.portkey_manager.create_embedding(
                provider="openai", model="text-embedding-3-small", input_text=query
            )

            if embedding_response and hasattr(embedding_response, "data"):
                vector = embedding_response.data[0].embedding

                # Search in Qdrant
                results = self.vector_db.search_vectors(
                    db_type="qdrant",
                    collection="sophia_knowledge",
                    query_vector=vector,
                    limit=limit,
                )

                return results
        except Exception as e:
            logger.error(f"Failed to search insights: {e}")
            return []

    async def health_check(self) -> dict[str, Any]:
        """Perform health check on Sophia factory"""
        portkey_health = self.portkey_manager.health_check()
        vector_db_health = self.vector_db.health_check()

        # Check specific business intelligence providers
        critical_providers = ["openai", "anthropic", "perplexity"]
        bi_health = all(portkey_health.get(p, False) for p in critical_providers)

        return {
            "status": "operational" if bi_health else "degraded",
            "business_intelligence_ready": bi_health,
            "portkey_providers": portkey_health,
            "vector_databases": vector_db_health,
            "factory": {
                "domain": self.domain,
                "critical_providers": critical_providers,
                "critical_providers_status": {
                    p: portkey_health.get(p, False) for p in critical_providers
                },
            },
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }


# Singleton instance
_portkey_sophia_factory: Optional[PortkeySophiaFactory] = None


def get_portkey_sophia_factory() -> PortkeySophiaFactory:
    """Get singleton instance of PortkeySophiaFactory"""
    global _portkey_sophia_factory
    if _portkey_sophia_factory is None:
        _portkey_sophia_factory = PortkeySophiaFactory()
    return _portkey_sophia_factory
