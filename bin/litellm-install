#!/usr/bin/env bash

# LiteLLM CLI Installation and Setup Script
# For ARM64/M3 Optimization

set -euo pipefail

GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[INSTALL]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Check prerequisites
check_prerequisites() {
    log "Checking prerequisites..."
    
    # Check uv
    if ! command -v uv > /dev/null; then
        error "uv is not installed. Install it with: curl -LsSf https://astral.sh/uv/install.sh | sh"
    fi
    
    # Check Python
    if ! command -v python3 > /dev/null; then
        error "Python 3 is not installed"
    fi
    
    # Check architecture
    if [[ "$(uname -m)" != "arm64" ]]; then
        warn "Not running on ARM64 architecture. Some optimizations may not apply."
    fi
    
    log "Prerequisites check passed"
}

# Install LiteLLM
install_litellm() {
    log "Installing LiteLLM in isolated environment..."
    
    local project_dir="/Users/lynnmusil/sophia-intel-ai"
    local venv_dir="$project_dir/.venv-litellm"
    
    # Create virtual environment
    if [[ ! -d "$venv_dir" ]]; then
        cd "$project_dir"
        uv venv --python 3.11 .venv-litellm
        log "Created virtual environment at $venv_dir"
    else
        log "Virtual environment already exists"
    fi
    
    # Install packages
    cd "$project_dir"
    source .venv-litellm/bin/activate
    
    log "Installing LiteLLM and dependencies..."
    uv pip install litellm[proxy] aiohttp pydantic fastapi uvicorn redis psutil
    
    # ARM64 specific optimizations
    if [[ "$(uname -m)" == "arm64" ]]; then
        log "Installing ARM64 optimizations..."
        uv pip install torch --index-url https://download.pytorch.org/whl/cpu
    fi
    
    log "LiteLLM installation complete"
}

# Setup configuration
setup_config() {
    log "Setting up configuration files..."
    
    local config_dir="/Users/lynnmusil/.config/litellm"
    mkdir -p "$config_dir"
    
    # Create shell profile entry
    local shell_profile=""
    if [[ -f "$HOME/.zshrc" ]]; then
        shell_profile="$HOME/.zshrc"
    elif [[ -f "$HOME/.bashrc" ]]; then
        shell_profile="$HOME/.bashrc"
    elif [[ -f "$HOME/.bash_profile" ]]; then
        shell_profile="$HOME/.bash_profile"
    fi
    
    if [[ -n "$shell_profile" ]]; then
        if ! grep -q "litellm-cli" "$shell_profile"; then
            echo "" >> "$shell_profile"
            echo "# LiteLLM CLI" >> "$shell_profile"
            echo "export PATH=\"/Users/lynnmusil/sophia-intel-ai/bin:\$PATH\"" >> "$shell_profile"
            echo "source /Users/lynnmusil/.config/litellm/environment.sh" >> "$shell_profile"
            log "Added LiteLLM CLI to $shell_profile"
        fi
    fi
    
    log "Configuration setup complete"
}

# Test installation
test_installation() {
    log "Testing installation..."
    
    local cli_path="/Users/lynnmusil/sophia-intel-ai/bin/litellm-cli"
    
    if [[ ! -x "$cli_path" ]]; then
        error "CLI script is not executable"
    fi
    
    # Test CLI help
    if "$cli_path" help > /dev/null; then
        log "CLI script is working"
    else
        error "CLI script failed"
    fi
    
    # Test virtual environment
    local venv_dir="/Users/lynnmusil/sophia-intel-ai/.venv-litellm"
    if [[ -d "$venv_dir" ]] && [[ -f "$venv_dir/bin/litellm" ]]; then
        log "Virtual environment and LiteLLM installation verified"
    else
        error "LiteLLM installation verification failed"
    fi
    
    log "Installation test passed"
}

# Create desktop shortcut (optional)
create_shortcuts() {
    log "Creating convenience shortcuts..."
    
    # Create symlink in /usr/local/bin if writable
    if [[ -w "/usr/local/bin" ]]; then
        ln -sf "/Users/lynnmusil/sophia-intel-ai/bin/litellm-cli" "/usr/local/bin/litellm-cli"
        log "Created system-wide shortcut at /usr/local/bin/litellm-cli"
    fi
    
    # Create alias suggestions
    cat << EOF

${GREEN}Installation Complete!${NC}

You can now use LiteLLM CLI with:
  /Users/lynnmusil/sophia-intel-ai/bin/litellm-cli

Or add this alias to your shell profile:
  alias litellm-cli='/Users/lynnmusil/sophia-intel-ai/bin/litellm-cli'

${YELLOW}Quick Start:${NC}
  litellm-cli start-proxy    # Start the proxy server
  litellm-cli test          # Test connectivity
  litellm-cli chat          # Interactive chat mode
  litellm-cli help          # Show all commands

${YELLOW}Configuration:${NC}
  Config: /Users/lynnmusil/.config/litellm/cli-config.yaml
  Environment: /Users/lynnmusil/.config/litellm/environment.sh

Restart your terminal or run: source ~/.zshrc (or ~/.bashrc)
EOF
}

# Main installation process
main() {
    log "Starting LiteLLM CLI installation for ARM64/M3..."
    
    check_prerequisites
    install_litellm
    setup_config
    test_installation
    create_shortcuts
    
    log "Installation completed successfully!"
}

# Run main function
main "$@"