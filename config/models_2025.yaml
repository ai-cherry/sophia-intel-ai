# 2025 Top Models Configuration
# Performance & Quality Focused - Latest Models from OpenRouter
# Updated: 2025-09-11

models:
  # TOP TIER - Latest & Greatest
  tier_1_flagship:
    - provider: openai
      model: gpt-5
      context: 256000
      performance: exceptional
      use_cases: [complex_reasoning, architecture, critical_decisions]
      
    - provider: anthropic
      model: claude-sonnet-4
      context: 200000
      performance: exceptional
      use_cases: [code_generation, analysis, creative_work]
      
    - provider: google
      model: gemini-2.5-pro
      context: 2000000
      performance: exceptional
      use_cases: [multimodal, long_context, research]

  # PERFORMANCE TIER - Fast & Powerful
  tier_2_performance:
    - provider: x-ai
      model: grok-code-fast-1
      context: 128000
      performance: blazing_fast
      use_cases: [rapid_prototyping, code_completion, quick_iterations]
      
    - provider: google
      model: gemini-2.5-flash
      context: 1000000
      performance: very_fast
      use_cases: [bulk_processing, quick_analysis, chat]
      
    - provider: google
      model: gemini-2.0-flash
      context: 1000000
      performance: very_fast
      use_cases: [streaming, real_time, interactive]
      
    - provider: deepseek
      model: deepseek-v3.1
      context: 128000
      performance: fast
      use_cases: [code_review, debugging, optimization]

  # SPECIALIZED TIER - Task-Specific Excellence
  tier_3_specialized:
    - provider: openrouter
      model: sonoma-sky-alpha
      context: 200000
      performance: optimized
      use_cases: [creative_writing, storytelling, narrative]
      
    - provider: openrouter
      model: sonoma-dusk-alpha
      context: 200000
      performance: optimized
      use_cases: [technical_writing, documentation, reports]
      
    - provider: qwen
      model: qwen3-30b-a3b
      context: 32768
      performance: balanced
      use_cases: [multilingual, translation, cross_cultural]
      
    - provider: z-ai
      model: glm-4.5
      context: 128000
      performance: balanced
      use_cases: [research, academic, scientific]

  # MINI TIER - Efficient but Powerful
  tier_4_mini:
    - provider: openai
      model: gpt-4.1-mini
      context: 128000
      performance: efficient
      use_cases: [quick_tasks, validation, lightweight]
      
    - provider: google
      model: gemini-2.5-flash-lite
      context: 1000000
      performance: ultra_fast
      use_cases: [streaming, edge_computing, mobile]
      
    - provider: google
      model: gemma-3-12b
      context: 8192
      performance: efficient
      use_cases: [local_deployment, privacy_focused, offline]

  # EXPERIMENTAL TIER - Cutting Edge
  tier_5_experimental:
    - provider: openai
      model: gpt-oss-120b
      context: 128000
      performance: experimental
      use_cases: [research, testing, benchmarking]
      
    - provider: deepseek
      model: deepseek-v3-0324
      context: 128000
      performance: experimental
      use_cases: [advanced_reasoning, mathematics, logic]
      
    - provider: anthropic
      model: claude-3.7-sonnet
      context: 200000
      performance: experimental
      use_cases: [next_gen_features, beta_testing]

# Flexible Routing Policies
routing_policies:
  # Quality First - Best possible output
  quality_max:
    primary:
      - openai/gpt-5
      - anthropic/claude-sonnet-4
      - google/gemini-2.5-pro
    fallback:
      - anthropic/claude-3.7-sonnet
      - openai/gpt-4.1-mini
    characteristics:
      - highest_accuracy
      - best_reasoning
      - premium_output

  # Speed Demon - Fastest response
  speed_max:
    primary:
      - x-ai/grok-code-fast-1
      - google/gemini-2.5-flash
      - google/gemini-2.0-flash
    fallback:
      - google/gemini-2.5-flash-lite
      - deepseek/deepseek-v3.1
    characteristics:
      - minimal_latency
      - high_throughput
      - real_time_capable

  # Code Master - Optimized for development
  code_specialist:
    primary:
      - x-ai/grok-code-fast-1
      - anthropic/claude-sonnet-4
      - deepseek/deepseek-v3.1
    fallback:
      - openai/gpt-5
      - deepseek/deepseek-v3-0324
    characteristics:
      - syntax_awareness
      - debugging_capable
      - refactoring_expert

  # Creative Genius - For creative tasks
  creative_max:
    primary:
      - openrouter/sonoma-sky-alpha
      - anthropic/claude-sonnet-4
      - openai/gpt-5
    fallback:
      - openrouter/sonoma-dusk-alpha
      - google/gemini-2.5-pro
    characteristics:
      - creative_writing
      - storytelling
      - ideation

  # Research Power - Deep analysis
  research_max:
    primary:
      - google/gemini-2.5-pro  # 2M context!
      - openai/gpt-5
      - z-ai/glm-4.5
    fallback:
      - anthropic/claude-sonnet-4
      - qwen/qwen3-30b-a3b
    characteristics:
      - long_context
      - fact_checking
      - comprehensive_analysis

  # Balanced Excellence - Best of all worlds
  balanced_performance:
    primary:
      - anthropic/claude-sonnet-4
      - google/gemini-2.5-flash
      - openai/gpt-4.1-mini
    fallback:
      - x-ai/grok-code-fast-1
      - deepseek/deepseek-v3.1
    characteristics:
      - good_speed
      - high_quality
      - versatile

# Dynamic Routing Rules
routing_rules:
  - condition: "task_length > 100000"
    use_policy: research_max
    reason: "Long context requires Gemini 2.5 Pro or GPT-5"
    
  - condition: "response_time_requirement < 500ms"
    use_policy: speed_max
    reason: "Ultra-low latency requires Grok or Gemini Flash"
    
  - condition: "task_type == 'code_generation'"
    use_policy: code_specialist
    reason: "Code tasks need specialized models"
    
  - condition: "quality_requirement == 'maximum'"
    use_policy: quality_max
    reason: "Critical tasks need best models"
    
  - condition: "task_type == 'creative_writing'"
    use_policy: creative_max
    reason: "Creative work needs specialized models"

# Provider Capabilities (2025)
provider_capabilities:
  openai:
    models_available: [gpt-5, gpt-4.1-mini, gpt-oss-120b]
    strengths: [reasoning, general_intelligence, consistency]
    api_version: "2025-01"
    
  anthropic:
    models_available: [claude-sonnet-4, claude-3.7-sonnet]
    strengths: [code, analysis, safety]
    api_version: "2025-01"
    
  google:
    models_available: [gemini-2.5-pro, gemini-2.5-flash, gemini-2.0-flash, gemini-2.5-flash-lite, gemma-3-12b]
    strengths: [multimodal, long_context, speed]
    api_version: "v2"
    
  x-ai:
    models_available: [grok-code-fast-1]
    strengths: [code, speed, efficiency]
    api_version: "v1"
    
  deepseek:
    models_available: [deepseek-v3.1, deepseek-v3-0324]
    strengths: [reasoning, mathematics, cost_efficiency]
    api_version: "v3"
    
  openrouter:
    models_available: [sonoma-sky-alpha, sonoma-dusk-alpha]
    strengths: [creative, narrative, specialized]
    api_version: "v1"

# Performance Metrics (2025 Benchmarks)
performance_benchmarks:
  gpt-5:
    mmlu: 96.8
    humaneval: 95.2
    latency_ms: 800
    tokens_per_sec: 120
    
  claude-sonnet-4:
    mmlu: 95.4
    humaneval: 94.8
    latency_ms: 600
    tokens_per_sec: 150
    
  grok-code-fast-1:
    mmlu: 92.1
    humaneval: 93.5
    latency_ms: 200
    tokens_per_sec: 400
    
  gemini-2.5-pro:
    mmlu: 94.9
    humaneval: 92.3
    latency_ms: 500
    tokens_per_sec: 200