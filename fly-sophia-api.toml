app = "sophia-api"
primary_region = "sjc"
kill_signal = "SIGINT"
kill_timeout = "5s"

[build]
  dockerfile = "Dockerfile.unified-api.production"

[env]
  PORT = "8003"
  PYTHONPATH = "/app"
  PYTHONUNBUFFERED = "1"
  LOCAL_DEV_MODE = "false"
  WEAVIATE_URL = "http://sophia-weaviate.internal:8080"
  MCP_SERVER_URL = "http://sophia-mcp.internal:8004"
  VECTOR_STORE_URL = "http://sophia-vector.internal:8005"
  DEFAULT_FAST_MODEL = "groq/llama-3.2-90b-text-preview"
  DEFAULT_BALANCED_MODEL = "openai/gpt-4o-mini"
  DEFAULT_HEAVY_MODEL = "anthropic/claude-3.5-sonnet"
  PORTKEY_BASE_URL = "https://api.portkey.ai/v1"
  USE_REAL_APIS = "true"
  ENABLE_API_VALIDATION = "true"
  FAIL_ON_MOCK_FALLBACK = "true"
  ENABLE_CONSENSUS_SWARMS = "true"
  ENABLE_MEMORY_DEDUPLICATION = "true"

[experimental]
  auto_rollback = true
  enable_consul = true

[services]
  protocol = "tcp"
  internal_port = 8003
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 2

  [[services.ports]]
    port = 80
    handlers = ["http"]
    force_https = true

  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]

  [services.concurrency]
    type = "connections"
    hard_limit = 250
    soft_limit = 200

  [[services.http_checks]]
    interval = "30s"
    grace_period = "10s"
    method = "GET"
    path = "/healthz"
    protocol = "http"
    timeout = "10s"
    tls_skip_verify = false

[mounts]
  source = "sophia_api_data"
  destination = "/data"
  initial_size = "15gb"

[[vm]]
  cpu_kind = "shared"
  cpus = 4.0
  memory_mb = 4096

[scaling]
  min_machines_running = 2
  max_machines_running = 20

  [[scaling.metrics]]
    type = "cpu"
    target = 70

  [[scaling.metrics]]
    type = "memory"
    target = 75