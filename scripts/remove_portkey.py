#!/usr/bin/env python3
"""
Remove Portkey integration and optimize OpenRouter for Sophia AI
"""
import os
import re
import json
from pathlib import Path

def remove_portkey_references():
    """Remove Portkey references from codebase"""
    print("üóëÔ∏è Removing Portkey Integration...")
    print("=" * 50)
    
    # Files to process
    files_to_update = [
        ".github/copilot-instructions.md",
        ".github/workflows/ci.yml", 
        ".github/workflows/consolidated-ci.yml",
        ".prompts/debug-issue.md",
        ".prompts/deploy-infra.md",
        "README.md",
        "requirements.txt",
        "infra/secrets.py",
        "infra/__main__.py"
    ]
    
    # Portkey-specific files to remove
    files_to_remove = [
        "services/portkey_client.py",
        "config/portkey_config.json",
        "scripts/test_portkey_fix.py"
    ]
    
    # Remove Portkey files
    for file_path in files_to_remove:
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"üóëÔ∏è Removed: {file_path}")
    
    # Update files to remove Portkey references
    for file_path in files_to_update:
        if os.path.exists(file_path):
            update_file_remove_portkey(file_path)
    
    print("\n‚úÖ Portkey integration removed successfully!")

def update_file_remove_portkey(file_path):
    """Update a file to remove Portkey references"""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        
        original_content = content
        
        # Remove Portkey-specific lines
        portkey_patterns = [
            r'.*PORTKEY.*\n',
            r'.*portkey.*\n',
            r'.*Portkey.*\n',
            r'.*from services\.portkey_client.*\n',
            r'.*PortkeyClient.*\n'
        ]
        
        for pattern in portkey_patterns:
            content = re.sub(pattern, '', content, flags=re.IGNORECASE)
        
        # Clean up empty lines
        content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
        
        if content != original_content:
            with open(file_path, 'w') as f:
                f.write(content)
            print(f"‚úÖ Updated: {file_path}")
        else:
            print(f"‚ÑπÔ∏è No changes needed: {file_path}")
            
    except Exception as e:
        print(f"‚ùå Error updating {file_path}: {e}")

def create_optimized_openrouter_client():
    """Create optimized OpenRouter client"""
    print("\nüöÄ Creating Optimized OpenRouter Client...")
    print("=" * 50)
    
    client_code = '''"""
Optimized OpenRouter client for Sophia AI
Direct integration without Portkey middleware
"""
import asyncio
import aiohttp
import json
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class OpenRouterModel:
    """OpenRouter model information"""
    id: str
    name: str
    description: str
    pricing: Dict[str, float]
    context_length: int
    architecture: Dict[str, Any]
    top_provider: Dict[str, Any]

class OpenRouterClient:
    """
    Optimized OpenRouter client with direct API access
    Features:
    - Direct API calls (no middleware)
    - Async/await support
    - Model selection optimization
    - Cost tracking
    - Retry logic with exponential backoff
    - Streaming support
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv('OPENROUTER_API_KEY')
        if not self.api_key:
            raise ValueError("OpenRouter API key is required")
        
        self.base_url = "https://openrouter.ai/api/v1"
        self.session = None
        self._models_cache = None
        
        # Default headers
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://sophia-intel.ai",
            "X-Title": "Sophia AI Platform"
        }
    
    async def __aenter__(self):
        """Async context manager entry"""
        self.session = aiohttp.ClientSession(headers=self.headers)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit"""
        if self.session:
            await self.session.close()
    
    async def get_models(self, force_refresh: bool = False) -> List[OpenRouterModel]:
        """Get available models with caching"""
        if self._models_cache and not force_refresh:
            return self._models_cache
        
        if not self.session:
            self.session = aiohttp.ClientSession(headers=self.headers)
        
        try:
            async with self.session.get(f"{self.base_url}/models") as response:
                if response.status == 200:
                    data = await response.json()
                    models = []
                    
                    for model_data in data.get('data', []):
                        model = OpenRouterModel(
                            id=model_data.get('id', ''),
                            name=model_data.get('name', ''),
                            description=model_data.get('description', ''),
                            pricing=model_data.get('pricing', {}),
                            context_length=model_data.get('context_length', 0),
                            architecture=model_data.get('architecture', {}),
                            top_provider=model_data.get('top_provider', {})
                        )
                        models.append(model)
                    
                    self._models_cache = models
                    logger.info(f"Loaded {len(models)} OpenRouter models")
                    return models
                else:
                    logger.error(f"Failed to fetch models: {response.status}")
                    return []
        except Exception as e:
            logger.error(f"Error fetching models: {e}")
            return []
    
    async def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "anthropic/claude-3.5-sonnet",
        max_tokens: int = 4000,
        temperature: float = 0.7,
        stream: bool = False,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Create chat completion with optimized model selection
        """
        if not self.session:
            self.session = aiohttp.ClientSession(headers=self.headers)
        
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "stream": stream,
            **kwargs
        }
        
        try:
            async with self.session.post(
                f"{self.base_url}/chat/completions",
                json=payload
            ) as response:
                
                if response.status == 200:
                    if stream:
                        return self._handle_stream_response(response)
                    else:
                        result = await response.json()
                        logger.info(f"Chat completion successful with {model}")
                        return result
                else:
                    error_text = await response.text()
                    logger.error(f"Chat completion failed: {response.status} - {error_text}")
                    raise Exception(f"OpenRouter API error: {response.status}")
                    
        except Exception as e:
            logger.error(f"Chat completion error: {e}")
            raise
    
    async def _handle_stream_response(self, response):
        """Handle streaming response"""
        async for line in response.content:
            if line:
                line = line.decode('utf-8').strip()
                if line.startswith('data: '):
                    data = line[6:]
                    if data != '[DONE]':
                        try:
                            yield json.loads(data)
                        except json.JSONDecodeError:
                            continue
    
    def get_recommended_models(self) -> Dict[str, str]:
        """Get recommended models for different use cases"""
        return {
            "reasoning": "anthropic/claude-3.5-sonnet",
            "coding": "anthropic/claude-3.5-sonnet",
            "creative": "anthropic/claude-3-opus",
            "fast": "anthropic/claude-3-haiku",
            "cost_effective": "meta-llama/llama-3.1-8b-instruct:free",
            "multimodal": "anthropic/claude-3.5-sonnet",
            "long_context": "anthropic/claude-3.5-sonnet"
        }
    
    async def estimate_cost(self, messages: List[Dict[str, str]], model: str) -> Dict[str, float]:
        """Estimate cost for a completion"""
        models = await self.get_models()
        model_info = next((m for m in models if m.id == model), None)
        
        if not model_info:
            return {"estimated_cost": 0.0, "input_tokens": 0, "output_tokens": 0}
        
        # Rough token estimation (4 chars = 1 token)
        input_tokens = sum(len(msg.get('content', '')) for msg in messages) // 4
        estimated_output_tokens = 500  # Default estimate
        
        pricing = model_info.pricing
        input_cost = (input_tokens / 1000000) * pricing.get('prompt', 0)
        output_cost = (estimated_output_tokens / 1000000) * pricing.get('completion', 0)
        
        return {
            "estimated_cost": input_cost + output_cost,
            "input_tokens": input_tokens,
            "output_tokens": estimated_output_tokens,
            "input_cost": input_cost,
            "output_cost": output_cost
        }

# Convenience functions for common operations
async def quick_chat(prompt: str, model: str = "anthropic/claude-3.5-sonnet") -> str:
    """Quick chat completion for simple prompts"""
    async with OpenRouterClient() as client:
        messages = [{"role": "user", "content": prompt}]
        response = await client.chat_completion(messages, model=model)
        return response['choices'][0]['message']['content']

async def get_available_models() -> List[str]:
    """Get list of available model IDs"""
    async with OpenRouterClient() as client:
        models = await client.get_models()
        return [model.id for model in models]

# Example usage
if __name__ == "__main__":
    async def test_client():
        async with OpenRouterClient() as client:
            # Test model listing
            models = await client.get_models()
            print(f"Available models: {len(models)}")
            
            # Test chat completion
            messages = [{"role": "user", "content": "Hello! How are you?"}]
            response = await client.chat_completion(messages)
            print(f"Response: {response['choices'][0]['message']['content']}")
            
            # Test cost estimation
            cost = await client.estimate_cost(messages, "anthropic/claude-3.5-sonnet")
            print(f"Estimated cost: ${cost['estimated_cost']:.6f}")
    
    asyncio.run(test_client())
'''
    
    # Write the optimized client
    os.makedirs('services', exist_ok=True)
    with open('services/openrouter_client.py', 'w') as f:
        f.write(client_code)
    
    print("‚úÖ Created optimized OpenRouter client: services/openrouter_client.py")

def update_requirements():
    """Update requirements.txt to remove Portkey and add OpenRouter dependencies"""
    print("\nüì¶ Updating Requirements...")
    print("=" * 50)
    
    # Read current requirements
    requirements = []
    if os.path.exists('requirements.txt'):
        with open('requirements.txt', 'r') as f:
            requirements = [line.strip() for line in f.readlines()]
    
    # Remove Portkey-related packages
    requirements = [req for req in requirements if 'portkey' not in req.lower()]
    
    # Add OpenRouter optimizations
    openrouter_deps = [
        'aiohttp>=3.8.0',
        'asyncio-throttle>=1.0.0'
    ]
    
    for dep in openrouter_deps:
        if not any(dep.split('>=')[0] in req for req in requirements):
            requirements.append(dep)
    
    # Write updated requirements
    with open('requirements.txt', 'w') as f:
        for req in sorted(requirements):
            if req.strip():
                f.write(f"{req}\n")
    
    print("‚úÖ Updated requirements.txt")

def create_openrouter_config():
    """Create OpenRouter configuration"""
    print("\n‚öôÔ∏è Creating OpenRouter Configuration...")
    print("=" * 50)
    
    config = {
        "openrouter": {
            "api_key_env": "OPENROUTER_API_KEY",
            "base_url": "https://openrouter.ai/api/v1",
            "default_model": "anthropic/claude-3.5-sonnet",
            "recommended_models": {
                "reasoning": "anthropic/claude-3.5-sonnet",
                "coding": "anthropic/claude-3.5-sonnet", 
                "creative": "anthropic/claude-3-opus",
                "fast": "anthropic/claude-3-haiku",
                "cost_effective": "meta-llama/llama-3.1-8b-instruct:free",
                "multimodal": "anthropic/claude-3.5-sonnet",
                "long_context": "anthropic/claude-3.5-sonnet"
            },
            "retry_config": {
                "max_retries": 3,
                "backoff_factor": 2,
                "timeout": 30
            },
            "cost_tracking": {
                "enabled": True,
                "daily_limit": 10.0,
                "alert_threshold": 8.0
            }
        }
    }
    
    os.makedirs('config', exist_ok=True)
    with open('config/openrouter_config.json', 'w') as f:
        json.dump(config, f, indent=2)
    
    print("‚úÖ Created OpenRouter configuration: config/openrouter_config.json")

def create_migration_guide():
    """Create migration guide from Portkey to OpenRouter"""
    print("\nüìñ Creating Migration Guide...")
    print("=" * 50)
    
    guide = '''# Migration Guide: Portkey ‚Üí OpenRouter Direct

## Overview
This migration removes the Portkey middleware and implements direct OpenRouter integration for improved performance, reduced complexity, and better cost control.

## Changes Made

### 1. Removed Files
- `services/portkey_client.py` - Replaced with `services/openrouter_client.py`
- `config/portkey_config.json` - Replaced with `config/openrouter_config.json`
- `scripts/test_portkey_fix.py` - No longer needed

### 2. Updated Files
- All workflow files (`.github/workflows/*.yml`)
- Documentation (`README.md`, `.prompts/*.md`)
- Infrastructure code (`infra/*.py`)
- Requirements (`requirements.txt`)

### 3. New Implementation
- **Direct API calls** to OpenRouter (no middleware)
- **Async/await support** for better performance
- **Built-in retry logic** with exponential backoff
- **Cost tracking and estimation**
- **Model recommendation system**
- **Streaming support**

## Code Migration

### Before (Portkey)
```python
from services.portkey_client import PortkeyClient

client = PortkeyClient()
response = await client.chat_completion(messages)
```

### After (Direct OpenRouter)
```python
from services.openrouter_client import OpenRouterClient

async with OpenRouterClient() as client:
    response = await client.chat_completion(messages)
```

## Environment Variables

### Removed
- `PORTKEY_API_KEY`
- `PORTKEY_CONFIG`

### Required
- `OPENROUTER_API_KEY` (existing, no change needed)

## Benefits

1. **Performance**: Direct API calls eliminate middleware latency
2. **Simplicity**: Fewer dependencies and configuration layers
3. **Cost Control**: Built-in cost estimation and tracking
4. **Reliability**: Custom retry logic optimized for OpenRouter
5. **Transparency**: Full control over API interactions

## Testing

Run the test script to verify the migration:
```bash
python3 scripts/test_openrouter_migration.py
```

## Rollback Plan

If needed, the previous Portkey integration can be restored from git history:
```bash
git checkout HEAD~1 -- services/portkey_client.py config/portkey_config.json
```
'''
    
    with open('docs/portkey_to_openrouter_migration.md', 'w') as f:
        f.write(guide)
    
    print("‚úÖ Created migration guide: docs/portkey_to_openrouter_migration.md")

def create_test_script():
    """Create test script for OpenRouter migration"""
    print("\nüß™ Creating Test Script...")
    print("=" * 50)
    
    test_code = '''#!/usr/bin/env python3
"""
Test OpenRouter migration and optimization
"""
import asyncio
import os
import sys
sys.path.append('.')

from services.openrouter_client import OpenRouterClient, quick_chat, get_available_models

async def test_openrouter_migration():
    """Test the OpenRouter migration"""
    print("üß™ Testing OpenRouter Migration...")
    print("=" * 50)
    
    # Check API key
    api_key = os.getenv('OPENROUTER_API_KEY')
    if not api_key:
        print("‚ùå OPENROUTER_API_KEY not found in environment")
        return False
    
    print(f"‚úÖ API key found: {api_key[:10]}...")
    
    try:
        # Test model listing
        print("\\nüìã Testing model listing...")
        models = await get_available_models()
        print(f"‚úÖ Found {len(models)} available models")
        
        # Test quick chat
        print("\\nüí¨ Testing quick chat...")
        response = await quick_chat("Say 'Hello from Sophia AI!' in exactly those words.")
        print(f"‚úÖ Quick chat response: {response[:100]}...")
        
        # Test full client
        print("\\nüîß Testing full client features...")
        async with OpenRouterClient() as client:
            # Test model recommendations
            recommendations = client.get_recommended_models()
            print(f"‚úÖ Model recommendations: {len(recommendations)} categories")
            
            # Test cost estimation
            messages = [{"role": "user", "content": "Hello!"}]
            cost = await client.estimate_cost(messages, "anthropic/claude-3.5-sonnet")
            print(f"‚úÖ Cost estimation: ${cost['estimated_cost']:.6f}")
            
            # Test chat completion
            response = await client.chat_completion(messages)
            print(f"‚úÖ Chat completion successful")
        
        print("\\nüéâ All tests passed! OpenRouter migration successful!")
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(test_openrouter_migration())
    sys.exit(0 if success else 1)
'''
    
    with open('scripts/test_openrouter_migration.py', 'w') as f:
        f.write(test_code)
    
    os.chmod('scripts/test_openrouter_migration.py', 0o755)
    print("‚úÖ Created test script: scripts/test_openrouter_migration.py")

def main():
    """Main function to execute Portkey removal and OpenRouter optimization"""
    print("üöÄ Portkey Removal & OpenRouter Optimization")
    print("=" * 60)
    
    # Step 1: Remove Portkey integration
    remove_portkey_references()
    
    # Step 2: Create optimized OpenRouter client
    create_optimized_openrouter_client()
    
    # Step 3: Update requirements
    update_requirements()
    
    # Step 4: Create OpenRouter configuration
    create_openrouter_config()
    
    # Step 5: Create migration documentation
    create_migration_guide()
    
    # Step 6: Create test script
    create_test_script()
    
    print("\\nüéâ Portkey removal and OpenRouter optimization completed!")
    print("\\nüìã Summary:")
    print("‚úÖ Removed Portkey integration completely")
    print("‚úÖ Created optimized OpenRouter client")
    print("‚úÖ Updated requirements and configurations")
    print("‚úÖ Created migration documentation")
    print("‚úÖ Created test script for validation")
    print("\\nüîÑ Next steps:")
    print("1. Test the migration: python3 scripts/test_openrouter_migration.py")
    print("2. Update any remaining code that imports Portkey")
    print("3. Commit changes to git")

if __name__ == "__main__":
    main()

