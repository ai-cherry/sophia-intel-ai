#!/usr/bin/env python3
"""
Test Portkey with OpenRouter as the unified provider.
"""

import asyncio
import os

import httpx
from dotenv import load_dotenv

from app.core.ai_logger import logger

# Load environment
load_dotenv(".env.local", override=True)


async def test_portkey_with_openrouter():
    """Test Portkey using OpenRouter as the provider for all models."""

    portkey_key = os.getenv("PORTKEY_API_KEY")
    openrouter_key = os.getenv("OPENROUTER_API_KEY")

    if not portkey_key or not openrouter_key:
        logger.info("‚ùå Missing API keys")
        return False

    logger.info("\n" + "=" * 60)
    logger.info("üîê Testing Portkey ‚Üí OpenRouter Integration")
    logger.info("=" * 60)

    # Test different models through Portkey ‚Üí OpenRouter
    test_cases = [
        {"name": "GPT-4 via OpenRouter", "model": "openai/gpt-4o-mini", "provider": "openrouter"},
        {
            "name": "Claude via OpenRouter",
            "model": "anthropic/claude-3-haiku-20240307",
            "provider": "openrouter",
        },
        {
            "name": "Llama via OpenRouter",
            "model": "meta-llama/llama-3.2-3b-instruct",
            "provider": "openrouter",
        },
        {
            "name": "Qwen Coder via OpenRouter",
            "model": "qwen/qwen-2.5-coder-32b-instruct",
            "provider": "openrouter",
        },
    ]

    async with httpx.AsyncClient(timeout=30.0) as client:
        for test in test_cases:
            logger.info(f"\nüìù Testing: {test['name']}")
            logger.info(f"   Model: {test['model']}")

            try:
                # Method 1: Using Portkey headers with OpenRouter provider
                response = await client.post(
                    "https://api.portkey.ai/v1/chat/completions",
                    headers={
                        "x-portkey-api-key": portkey_key,
                        "x-portkey-provider": test["provider"],
                        "x-portkey-api-key-openrouter": openrouter_key,  # Pass OpenRouter key
                        "Content-Type": "application/json",
                        "HTTP-Referer": "http://localhost:3000",  # Required by OpenRouter
                        "X-Title": "Sophia Intel AI",  # Required by OpenRouter
                    },
                    json={
                        "model": test["model"],
                        "messages": [{"role": "user", "content": "Say 'Hello' in one word"}],
                        "max_tokens": 10,
                        "temperature": 0.1,
                    },
                )

                if response.status_code == 200:
                    result = response.json()
                    content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                    logger.info(f"   ‚úÖ Success! Response: {content[:50]}")
                else:
                    logger.info(f"   ‚ùå Failed: Status {response.status_code}")
                    if response.status_code == 401:
                        logger.info("      ‚Üí Need to configure virtual key in Portkey dashboard")
                    try:
                        error = response.json()
                        logger.info(
                            f"      ‚Üí Error: {error.get('error', {}).get('message', 'Unknown')}"
                        )
                    except:
                        pass

            except Exception as e:
                logger.info(f"   ‚ùå Error: {str(e)[:100]}")

    logger.info("\n" + "=" * 60)
    logger.info("üìä Configuration Instructions")
    logger.info("=" * 60)

    print(
        """
To make this work, in Portkey dashboard:

1. Create a Virtual Key with:
   - Provider: OpenRouter
   - API Key: Your OpenRouter key
   - Name: openrouter-unified

2. Then use the virtual key ID in your code:
   ```python
   client = OpenAI(
       api_key="<virtual-key-id>",
       base_url="https://api.portkey.ai/v1"
   )
   ```

3. Benefits:
   - Access to 300+ models with one key
   - Portkey's caching and observability
   - Automatic fallbacks
   - Cost tracking
    """
    )

    return True


async def test_direct_openrouter():
    """Test OpenRouter directly to confirm it works."""

    openrouter_key = os.getenv("OPENROUTER_API_KEY")

    if not openrouter_key:
        logger.info("‚ùå OpenRouter key not found")
        return False

    logger.info("\nüîç Testing Direct OpenRouter Connection...")

    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {openrouter_key}",
                "HTTP-Referer": "http://localhost:3000",
                "X-Title": "Sophia Intel AI",
                "Content-Type": "application/json",
            },
            json={
                "model": "meta-llama/llama-3.2-3b-instruct",  # Cheap, fast model
                "messages": [{"role": "user", "content": "Say 'working' in one word"}],
                "max_tokens": 10,
            },
        )

        if response.status_code == 200:
            result = response.json()
            content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
            logger.info(f"‚úÖ OpenRouter Direct: Working! Response: {content}")
            return True
        else:
            logger.info(f"‚ùå OpenRouter Direct: Failed ({response.status_code})")
            return False


async def main():
    """Run all tests."""

    # Test direct OpenRouter first
    openrouter_ok = await test_direct_openrouter()

    if openrouter_ok:
        logger.info("\n‚úÖ OpenRouter is working directly")
        logger.info("Now testing Portkey integration...")

    # Test Portkey with OpenRouter
    await test_portkey_with_openrouter()

    logger.info("\n" + "=" * 60)
    logger.info("‚ú® Summary")
    logger.info("=" * 60)
    print(
        """
Your setup:
‚úÖ OpenRouter API key is valid and working
‚úÖ Access to 300+ models through OpenRouter
‚ö†Ô∏è  Portkey needs virtual key configuration

Next step:
1. Go to https://app.portkey.ai
2. Create virtual key with OpenRouter as provider
3. Use your OpenRouter API key in the virtual key
4. You'll have unified access to all models!
    """
    )


if __name__ == "__main__":
    asyncio.run(main())
